from __future__ import division
import os
import sys
import random
import subprocess
import pickle
import math
import numpy
import scipy
import sklearn
from sklearn.ensemble import RandomForestClassifier
from sklearn import preprocessing
from sklearn import cross_validation
from sklearn import neighbors
from sklearn import metrics
from sklearn import svm
from sklearn import ensemble
from sklearn.externals import joblib
import compiler

filename=open("outputs/SVM.dat","r") #ENSP00000266679 -1 0.828195657369 0.0355613421217 1 0 6
checkarray=[]
ll=[]
data = numpy.zeros([300, 5])
print data
raw=0

for line in filename:
	check=""
	print "line",line
	if check not in checkarray:
		if (int(line.split()[1])==1) and (ll.count(1)<150):
			ll.append(int(line.split()[1]))
			for a in range(2,len(line.split())):	
				value=float(line.split()[a])
				data[raw,a-2]=value
				check+=line.split()[a]+" "
			#print "check",check
			raw+=1
			checkarray.append(check)

		if (int(line.split()[1])==-1) and (ll.count(-1)<150):
			ll.append(int(line.split()[1]))
			for a in range(2,len(line.split())):	
				value=float(line.split()[a])
				data[raw,a-2]=value
				check+=line.split()[a]+" "
			#print "check",check
			raw+=1
			checkarray.append(check)


filename.close()
print data, data.shape
labels=numpy.array(ll)
n_features=data.shape[1]



for scoreVal in ['accuracy', 'adjusted_rand_score', 'average_precision', 'f1', 'log_loss', 'mean_squared_error', 'precision', 'r2', 'recall', 'roc_auc']:

	print "ExtraTree"
	Xtree=open("ExtraTree/"+scoreVal+".results","w")
	Xtree.write("#1 2 3 4 5 6 7 8 9 10 mean\n")
	crossval_scores = []
	crossval_values = cross_validation.cross_val_score(ensemble.ExtraTreesClassifier() , data, labels, cv=10,scoring=scoreVal)    
	text=""
	for a in crossval_values:
		text+=str(round(a,2))+" "
	Xtree.write(text+" "+str(numpy.mean(crossval_values))+"\n")
	print crossval_values
	#model=ensemble.ExtraTreesClassifier() 
	#model.fit(data, labels)
	#joblib.dump(model, "ExtraTree/"+scoreVal+".model")	
	Xtree.close()

	print "AdaBoost"
	adaB=open("AdaBoost/"+scoreVal+".results","w")
	adaB.write("#parameter 1 2 3 4 5 6 7 8 9 10 mean\n")
	for nesti in range(1,30):
		crossval_scores = []
		crossval_values = cross_validation.cross_val_score(ensemble.AdaBoostClassifier(n_estimators=nesti) , data, labels, cv=10,scoring=scoreVal)    
		text=""
		#model=ensemble.AdaBoostClassifier(n_estimators=nesti)
		#model.fit(data, labels)
		#joblib.dump(model, "AdaBoost/"+scoreVal+"_"+str(nesti)+".model")	
		for a in crossval_values:
			text+=str(round(a,2))+" "
		#print text
		adaB.write(str(nesti)+" "+text+" "+str(numpy.mean(crossval_values))+"\n")
	print crossval_values
	adaB.close()






for scoreVal in ['accuracy', 'adjusted_rand_score', 'average_precision', 'f1', 'log_loss', 'mean_squared_error', 'precision', 'r2', 'recall', 'roc_auc']:
	SVMpoly=open("SVMPoly/"+scoreVal+".results","w")
	SVMpoly.write("degree cost gamma 1 2 3 4 5 6 7 8 9 10 mean\n")
	print "SVM poly"
	for degree in range(1,6):
		
		for c in range(-5,5):
			cost=pow(2,c)
			for g in range(-5,5):
				gamma=pow(2,g)	
				crossval_scores = []

				crossval_values = cross_validation.cross_val_score( svm.SVC(kernel='poly', degree=degree,gamma=gamma, C=cost), data, labels, cv=10,scoring=scoreVal) 
					#print crossval_values
				text=""
				#model=svm.SVC(kernel='poly', degree=degree,gamma=gamma, C=cost)
				#model.fit(data, labels)
				#joblib.dump(model, "SVMPoly/degree"+scoreVal+"_"+str(cost)+"_"+str(gamma)+".model")	
				for a in crossval_values:
					text+=str(round(a,2))+" "
				#print text
				SVMpoly.write(str(degree)+" "+str(cost)+" "+str(gamma)+" "+text+" "+str(numpy.mean(crossval_values))+"\n")
	SVMpoly.close()



for scoreVal in ['accuracy', 'adjusted_rand_score', 'average_precision', 'f1', 'log_loss', 'mean_squared_error', 'precision', 'r2', 'recall', 'roc_auc']:


	print "SVM rbf"

	SVMrbf=open("SVMrbf/"+scoreVal+".results","w")
	SVMrbf.write("#cost gamma 1 2 3 4 5 6 7 8 9 10 mean\n")
	for c in range(-5,5):
		cost=pow(2,c)
		for g in range(-5,5):
			gamma=pow(2,g)	
			crossval_scores = []
			crossval_values = cross_validation.cross_val_score( svm.SVC(kernel='rbf',probability=True,gamma=gamma, C=cost), data, labels, cv=10,scoring=scoreVal) 
			#print crossval_values
			#model=svm.SVC(kernel='rbf',probability=True,gamma=gamma, C=cost)
			#model.fit(data, labels)
			#joblib.dump(model, "SVMrbf/"+scoreVal+"_"+str(cost)+"_"+str(gamma)+".model")		
			text=""
			for a in crossval_values:
				text+=str(round(a,2))+" "
			#print text
			SVMrbf.write(str(cost)+" "+str(gamma)+" "+text+" "+str(numpy.mean(crossval_values))+"\n")
	SVMrbf.close()

for scoreVal in ['accuracy', 'adjusted_rand_score', 'average_precision', 'f1', 'log_loss', 'mean_squared_error', 'precision', 'r2', 'recall', 'roc_auc']:
	print "SVM linear"
	SVMlinear=open("SVMlinear/"+scoreVal+".results","w")
	SVMlinear.write("cost1 2 3 4 5 6 7 8 9 10 mean\n")
	for c in range(-5,5):
		cost=pow(2,c)
		crossval_scores = []
		crossval_values = cross_validation.cross_val_score( svm.SVC(kernel='linear',probability=True, C=cost), data, labels, cv=10,scoring=scoreVal) 
					#print crossval_values
		#model=svm.SVC(kernel='linear',probability=True, C=cost)
		#model.fit(data, labels)
		#joblib.dump(model, "SVMlinear/"+scoreVal+"_"+str(cost)+".model")		
		text=""
		for a in crossval_values:
			text+=str(round(a,2))+" "
		#print text
		SVMlinear.write(str(cost)+" "+text+" "+str(numpy.mean(crossval_values))+"\n")
	SVMlinear.close()



for scoreVal in ['accuracy', 'adjusted_rand_score', 'average_precision', 'f1', 'log_loss', 'mean_squared_error', 'precision', 'r2', 'recall', 'roc_auc']:
	print "KNN"
	KNN=open("KNN/"+scoreVal+".results","w")
	KNN.write("#num_N 1 2 3 4 5 6 7 8 9 10 mean\n")
	for num_neighbours in range(3,50):
		crossval_scores = []
		crossval_values = cross_validation.cross_val_score(neighbors.KNeighborsClassifier(n_neighbors=num_neighbours, algorithm='kd_tree') , data, labels, cv=10,scoring=scoreVal)    	
		text=""
		for a in crossval_values:
			text+=str(round(a,2))+" "
		#print text
		#model=neighbors.KNeighborsClassifier(n_neighbors=num_neighbours, algorithm='kd_tree')
		#model.fit(data, labels)
		#joblib.dump(model, "KNN/"+scoreVal+"_"+str(num_neighbours)+".model")	
		KNN.write(str(num_neighbours)+" "+text+" "+str(numpy.mean(crossval_values))+"\n")
	KNN.close()






##final model training














crossi = cross_validation.StratifiedKFold(labels, n_folds=10)

split=0
print "method split prec recall MCC auc f1 acc"
for train_index, test_index in crossi:
	split+=1
#	print split 
	train, test = data[train_index], data[test_index]
	trainlabel, testlabel = labels[train_index], labels[test_index]
	if True:	

		#KNN=open("KNN/"+scoreVal+".results","w")
		#KNN.write("#num_N 1 2 3 4 5 6 7 8 9 10 mean\n")
		num_neighbours=29
	#	crossval_values = cross_validation.cross_val_score(neighbors.KNeighborsClassifier(n_neighbors=num_neighbours, algorithm='kd_tree') , data, labels, cv=10,scoring=scoreVal)    	
		model=neighbors.KNeighborsClassifier(n_neighbors=num_neighbours, algorithm='kd_tree')
		model.fit(train,trainlabel)
		model.predict(test)
		model.predict_proba(test)
		cm = metrics.confusion_matrix(testlabel, model.predict(test)) #confusion_matrix(y_true, y_pred[, labels])
		joblib.dump(model, "KNN/Final"+str(split)+"_"+str(num_neighbours)+".model")	
	
		acc=metrics.accuracy_score(testlabel,model.predict(test))#accuracy_score(y_true, y_pred[, normalize])	Accuracy classification score.
	#	print metrics.classification_report(testlabel,model.predict(test))#	Build a text report showing the main classification metrics
		f1=metrics.f1_score(testlabel,model.predict(test))#	Compute the F1 score, also known as balanced F-score or F-measure
		MCC=metrics.matthews_corrcoef(testlabel,model.predict(test))#matthews_corrcoef(y_true, y_pred)	Compute the Matthews correlation coefficient (MCC) for binary classes
		prec=metrics.precision_score(testlabel, model.predict(test))#	Compute the precision
		recall=metrics.recall_score(testlabel, model.predict(test))#	Compute the recall
		auc=metrics.roc_auc_score(testlabel,model.predict(test))#roc_auc_score(y_true, y_score)	Compute Area Under the Curve (AUC) from prediction scores
	#	roc_curve(y_true, y_score[, pos_label])	Compute Receiver operating characteristic (ROC)
		print "KNN ",split,prec,recall,MCC,auc,f1,acc 



		scoreVal = ['accuracy', 'adjusted_rand_score', 'average_precision', 'f1', 'log_loss', 'mean_squared_error', 'precision', 'r2', 'recall', 'roc_auc']
		print "RF"
		RandFor=open("RandFor/"+scoreVal+".results","w")
		RandFor.write("#treenumber 1 2 3 4 5 6 7 8 9 10 mean\n")

		for treenumber in range(5,50):
			crossval_scores = []
			crossval_values = cross_validation.cross_val_score( RandomForestClassifier(n_estimators=treenumber,criterion='gini', max_features=n_features,max_depth=None,min_samples_split=1), data, labels, cv=10,scoring=scoreVal) 
			model = RandomForestClassifier(n_estimators=treenumber,criterion='gini', max_features=n_features,max_depth=None,min_samples_split=1)
			model.fit(data, labels)
			joblib.dump(model, "RandFor/"+scoreVal+"_"+str(treenumber)+".model")	
			#print crossval_values
			text=""
			for a in crossval_values:
				text+=str(round(a,2))+" "
			#print text
			RandFor.write(str(treenumber)+" "+text+" "+str(numpy.mean(crossval_values))+"\n")
		RandFor.close()


	
	print "SVM poly"
	for degree in range(1,6):
		SVMpoly=open("SVMPoly/"+str(degree)+".results"+scoreVal,"w")
		SVMpoly.write("degree cost gamma 1 2 3 4 5 6 7 8 9 10 mean\n")
		for c in range(-5,5):
			cost=pow(2,c)
			for g in range(-5,5):
				gamma=pow(2,g)	
				crossval_scores = []

				crossval_values = cross_validation.cross_val_score( svm.SVC(kernel='poly', degree=degree,gamma=gamma, C=cost), data, labels, cv=10,scoring=scoreVal) 
					#print crossval_values
				text=""
				#model=svm.SVC(kernel='poly', degree=degree,gamma=gamma, C=cost)
				#model.fit(data, labels)
				#joblib.dump(model, "SVMPoly/degree"+scoreVal+"_"+str(cost)+"_"+str(gamma)+".model")	
				for a in crossval_values:
					text+=str(round(a,2))+" "
				#print text
				SVMpoly.write(str(degree)+" "+str(cost)+" "+str(gamma)+" "+text+" "+str(numpy.mean(crossval_values))+"\n")
		SVMpoly.close()

	print "SVM rbf"
	
	scoreVal = ['accuracy', 'adjusted_rand_score', 'average_precision', 'f1', 'log_loss', 'mean_squared_error', 'precision', 'r2', 'recall', 'roc_auc']:
	SVMrbf=open("SVMrbf/"+scoreVal+".results","w")
	SVMrbf.write("#cost gamma 1 2 3 4 5 6 7 8 9 10 mean\n")
	for c in range(-5,5):
		cost=pow(2,c)
		for g in range(-5,5):
			gamma=pow(2,g)	
			crossval_scores = []
			crossval_values = cross_validation.cross_val_score( svm.SVC(kernel='rbf',probability=True,gamma=gamma, C=cost), data, labels, cv=10,scoring=scoreVal) 
			#print crossval_values
			#model=svm.SVC(kernel='rbf',probability=True,gamma=gamma, C=cost)
			#model.fit(data, labels)
			#joblib.dump(model, "SVMrbf/"+scoreVal+"_"+str(cost)+"_"+str(gamma)+".model")		
			text=""
			for a in crossval_values:
				text+=str(round(a,2))+" "
			#print text
			SVMrbf.write(str(cost)+" "+str(gamma)+" "+text+" "+str(numpy.mean(crossval_values))+"\n")
	SVMrbf.close()
	
	scoreVal = ['accuracy', 'adjusted_rand_score', 'average_precision', 'f1', 'log_loss', 'mean_squared_error', 'precision', 'r2', 'recall', 'roc_auc']:
	print "SVM linear"
	SVMlinear=open("SVMlinear/"+scoreVal+".results","w")
	SVMlinear.write("cost1 2 3 4 5 6 7 8 9 10 mean\n")
	for c in range(-5,5):
		cost=pow(2,c)
		crossval_scores = []
		crossval_values = cross_validation.cross_val_score( svm.SVC(kernel='linear',probability=True, C=cost), data, labels, cv=10,scoring=scoreVal) 
					#print crossval_values
		#model=svm.SVC(kernel='linear',probability=True, C=cost)
		#model.fit(data, labels)
		#joblib.dump(model, "SVMlinear/"+scoreVal+"_"+str(cost)+".model")		
		text=""
		for a in crossval_values:
			text+=str(round(a,2))+" "
		#print text
		SVMlinear.write(str(cost)+" "+text+" "+str(numpy.mean(crossval_values))+"\n")
	SVMlinear.close()


	scoreVal = ['accuracy', 'adjusted_rand_score', 'average_precision', 'f1', 'log_loss', 'mean_squared_error', 'precision', 'r2', 'recall', 'roc_auc']:
	print "ExtraTree"
	Xtree=open("ExtraTree/"+scoreVal+".results","w")
	Xtree.write("#1 2 3 4 5 6 7 8 9 10 mean\n")
	crossval_scores = []
	crossval_values = cross_validation.cross_val_score(ensemble.ExtraTreesClassifier() , data, labels, cv=10,scoring=scoreVal)    
	text=""
	for a in crossval_values:
		text+=str(round(a,2))+" "
	Xtree.write(text+" "+str(numpy.mean(crossval_values))+"\n")
	print crossval_values
	#model=ensemble.ExtraTreesClassifier() 
	#model.fit(data, labels)
	#joblib.dump(model, "ExtraTree/"+scoreVal+".model")	
	Xtree.close()


	scoreVal = ['accuracy', 'adjusted_rand_score', 'average_precision', 'f1', 'log_loss', 'mean_squared_error', 'precision', 'r2', 'recall', 'roc_auc']:
	print "AdaBoost"
	adaB=open("AdaBoost/"+scoreVal+".results","w")
	adaB.write("#parameter 1 2 3 4 5 6 7 8 9 10 mean\n")
	for nesti in range(1,30):
		crossval_scores = []
		crossval_values = cross_validation.cross_val_score(ensemble.AdaBoostClassifier(n_estimators=nesti) , data, labels, cv=10,scoring=scoreVal)    
		text=""
		#model=ensemble.AdaBoostClassifier(n_estimators=nesti)
		#model.fit(data, labels)
		#joblib.dump(model, "AdaBoost/"+scoreVal+"_"+str(nesti)+".model")	
		for a in crossval_values:
			text+=str(round(a,2))+" "
		#print text
		adaB.write(str(nesti)+" "+text+" "+str(numpy.mean(crossval_values))+"\n")
	print crossval_values
	adaB.close()


	#################R script ############################

